{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2_60_local.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TXJjQndCCWN"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QsEWdQrKw9U"
      },
      "source": [
        "# 自动下载数据集\n",
        "\n",
        "import os\n",
        "# TinyImageNet\n",
        "if not os.path.exists(\"./TinyImageNet\"):\n",
        "  !kaggle datasets download -d mikewallace250/tiny-imagenet-challenge\n",
        "  !unzip tiny-imagenet-challenge.zip > /dev/null\n",
        "  !rm tiny-imagenet-challenge.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBOF3TAIE7m3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "img = mpimg.imread('TinyImageNet/val/6/6_1087.jpg').astype(int)\n",
        "print(img.shape)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMpQRO-8L7lP"
      },
      "source": [
        "# custom transform objects\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "\n",
        "class MyNormalize(object):\n",
        "    \"\"\"Normalize a image tensor\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, data): # assumes the same shape as an image tensor\n",
        "      assert(len(data.shape) == 3)\n",
        "      # mean = []\n",
        "      # std = []\n",
        "      # for i in range(3):\n",
        "      #   mean.append(torch.mean(data[i]))\n",
        "      #   std.append(torch.std(data[i]))\n",
        "      # transforms.Normalize(mean, std, inplace=True)(data)\n",
        "      data = data / 255\n",
        "      transforms.Normalize(mean = (0.4650,0.4516,0.3871),std=(0.2671,0.2579,0.2722), inplace=True)(data)\n",
        "      return data\n",
        "\n",
        "class MyAugmentation(object):\n",
        "    \"\"\"Augment a image tensor or a batch of image tensors\n",
        "        Uses the below transforms randomly\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, image): \n",
        "      image = transforms.RandomHorizontalFlip()(image)\n",
        "      image = transforms.RandomGrayscale()(image)\n",
        "      if random.random() < 0.5:\n",
        "        image = transforms.RandomRotation(15)(image)\n",
        "      # I didn't add cropping because it might hurt ImageNet-A performance \n",
        "      # image = image.RandomCrop(64, pad_if_needed=True)\n",
        "      return image\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvR_shx3admY"
      },
      "source": [
        "# load_data.py\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import time\n",
        "\n",
        "class TINDataset(torch.utils.data.Dataset):\n",
        "  \"\"\" TinyImageNet Dataset \"\"\"\n",
        "  TRAIN = 0\n",
        "  VALIDATE = 1\n",
        "  TEST = 9\n",
        "  _status = TRAIN # mark the current state of the dataset\n",
        "  \n",
        "  def __init__(self, args):\n",
        "    self.train_loc = args.train_loc\n",
        "    self.val_loc = args.val_loc\n",
        "    self.test_loc = args.test_loc\n",
        "\n",
        "    self.train_label = torch.mul(torch.LongTensor([i for i in range(100)]).view(-1,1), torch.ones(1000).long().view(1,-1)).view(-1)\n",
        "    self.val_label = torch.mul(torch.LongTensor([i for i in range(200)]).view(-1,1), torch.ones(100).long().view(1,-1)).view(-1)\n",
        "\n",
        "    # 对输入矩阵进行转置、转化为tensor、中心化\n",
        "    #trans = transforms.Compose([transforms.ToTensor()])\n",
        "    #trans = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean = (118.57,115.17,98.72),std=(68.10,65.77,69.41))])\n",
        "    trans = transforms.Compose([transforms.ToTensor(), MyNormalize()])\n",
        "    time_start = 0\n",
        "    time_end = 0\n",
        "    print(\"----------Loading training data----------\")\n",
        "    time_start = time.time()\n",
        "    print('train_loc:',self.train_loc)\n",
        "    self.train_data = torch.zeros(100 * 1000, 3, 64, 64)\n",
        "    for i in range(100):\n",
        "      for j in range(1000):\n",
        "        filename = self.train_loc+str(i)+'/'+str(i)+'_'+str(j)+'.jpg'\n",
        "        self.train_data[i * 1000 + j] = trans(mpimg.imread(filename).astype(float))\n",
        "    print('size:',self.train_data.shape)\n",
        "    time_end = time.time()\n",
        "    print(\"Total time: {:.2f}min\".format((time_end - time_start) / 60))\n",
        "    print(\"--------------Finish loading--------------\")\n",
        "\n",
        "    print(\"----------Loading validation data----------\")\n",
        "    time_start = time.time()\n",
        "    print('validation_loc:',self.val_loc)\n",
        "    self.val_data = torch.zeros(100 * 100, 3, 64, 64)\n",
        "    for i in range(100):\n",
        "      for j in range(100):\n",
        "        filename = self.val_loc+str(i)+'/'+str(i)+'_10'+str(j).rjust(2,'0')+'.jpg'\n",
        "        self.val_data[i * 100 + j] = trans(mpimg.imread(filename).astype(float))\n",
        "    \n",
        "    print('size:',self.val_data.shape)\n",
        "    time_end = time.time()\n",
        "    print(\"Total time: {:.2f}min\".format((time_end - time_start) / 60))\n",
        "    print(\"--------------Finish loading--------------\")\n",
        "\n",
        "    print(\"----------Loading test data----------\")\n",
        "    time_start = time.time()\n",
        "    print('test_loc:',self.test_loc)\n",
        "    self.test_data = torch.zeros(10000, 3, 64, 64)\n",
        "    for i in range(10000):\n",
        "        filename = self.test_loc+str(i)+'.jpg'\n",
        "        self.test_data[i] = trans(mpimg.imread(filename).astype(float))\n",
        "    print('size:',self.test_data.shape)\n",
        "    time_end = time.time()\n",
        "    print(\"Total time: {:.2f}min\".format((time_end - time_start) / 60))\n",
        "    print(\"--------------Finish loading--------------\")\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    if self._status == self.TRAIN:\n",
        "      return self.train_data[index], self.train_label[index] # data, label(target)\n",
        "    elif self._status == self.VALIDATE:\n",
        "      return self.val_data[index], self.val_label[index]\n",
        "    else:\n",
        "      return self.test_data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    if self._status == self.TRAIN:\n",
        "      return self.train_data.shape[0]\n",
        "    elif self._status == self.VALIDATE:\n",
        "      return self.val_data.shape[0]\n",
        "    else:\n",
        "      return self.test_data.shape[0]\n",
        "  \n",
        "  def train(self):\n",
        "    self._status = self.TRAIN\n",
        "\n",
        "  def validate(self):\n",
        "    self._status = self.VALIDATE\n",
        "\n",
        "  def test(self):\n",
        "    # if self._status != self.TEST:\n",
        "    #   del self.train_data\n",
        "    #   del self.train_label\n",
        "    #   del self.val_data\n",
        "    #   del self.val_label\n",
        "    self._status = self.TEST\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOvndmZ90qVV"
      },
      "source": [
        "# config.py\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "!mkdir log > /dev/null\n",
        "\n",
        "class Config(object):\n",
        "    def __init__(self, model_name):\n",
        "        self.batch_size = 32\n",
        "        self.test_batch_size = 10\n",
        "        self.max_epoch = 20\n",
        "        self.class_num = 100\n",
        "        self.learning_rate = 0.003\n",
        "        self.drop_rate = 0.1\n",
        "        self.test_epoch = 1\n",
        "        self.save_path = './checkpoint'\n",
        "        if not os.path.exists(self.save_path):\n",
        "            os.mkdir(self.save_path)\n",
        "        self.model_name = model_name\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.aug = MyAugmentation()\n",
        "\n",
        "    def logging(self, s, print_=True, log_=True):\n",
        "        if print_:\n",
        "            print(s)\n",
        "        if log_:\n",
        "            with open(os.path.join(os.path.join(\"log\", self.model_name)), 'a+') as f_log:\n",
        "                f_log.write(s + '\\n')\n",
        "\n",
        "    def train(self, model, optimizer, criterion, dataset):\n",
        "        self.logging(\"Training Started, using \" + str(criterion) + \" and \" + str(optimizer) + \"\\n\\n\")\n",
        "        losses = []\n",
        "        best_acc = 0.0\n",
        "        best_epoch = 0\n",
        "        model.train()\n",
        "        dataset.train()\n",
        "        train_loader = DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        for epoch in range(self.max_epoch):\n",
        "            train_loss = 0.0\n",
        "            start_time = time.time()\n",
        "            train_total = train_correct = 0\n",
        "\n",
        "            for data,target in train_loader:\n",
        "                data = self.aug(data).to(self.device)\n",
        "                target = target.to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "                output = model(data) #得到预测值\n",
        "\n",
        "                loss = criterion(output,target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()*data.size(0)\n",
        "\n",
        "                pred = torch.argmax(output, dim=-1).cpu()\n",
        "                train_total += len(pred)\n",
        "                train_correct += int(torch.sum(pred == target.squeeze(-1).cpu()))\n",
        "\n",
        "            train_loss = train_loss / len(train_loader.dataset)\n",
        "            losses.append(train_loss)\n",
        "            if train_total > 0:\n",
        "                acc = train_correct / train_total\n",
        "            else:\n",
        "                acc = 0.0\n",
        "            self.logging('[Epoch {:d}] Training Loss: {:.6f}; Time: {:.2f}min; Acc: {:.4f}'.format(\n",
        "            epoch + 1, train_loss, (time.time()-start_time)/60, acc))\n",
        "            if (epoch + 1) % self.test_epoch == 0:\n",
        "                self.logging('-' * 70)\n",
        "                eval_start_time = time.time()\n",
        "                model.eval()\n",
        "                dataset.validate()\n",
        "                val_acc = self.test(model, dataset)\n",
        "                self.logging('Validate\\nTime: {:.2f}min; Accuracy: {:.4f}'.format(\n",
        "                    (time.time()-eval_start_time)/60, val_acc))\n",
        "                if val_acc > best_acc:\n",
        "                    best_acc = val_acc\n",
        "                    best_epoch = epoch + 1\n",
        "                    torch.save(model.state_dict(),os.path.join(self.save_path, self.model_name))\n",
        "                model.train()\n",
        "                dataset.train()\n",
        "                self.logging('-' * 70)\n",
        "        self.logging('Training finished!')\n",
        "        self.logging('Best epoch: {:d} | acc: {:.4f}'.format(best_epoch, best_acc))\n",
        "        return losses\n",
        "    \n",
        "    def test(self, model, dataset):\n",
        "        data_loader = DataLoader(dataset=dataset, batch_size=self.test_batch_size, shuffle=False)\n",
        "        total = correct = 0\n",
        "        for data, target in data_loader:\n",
        "                data = data.to(self.device)\n",
        "                target = target.to(self.device)\n",
        "                output = model(data).cpu()\n",
        "                # convert output probabilities to predicted class\n",
        "                pred = torch.argmax(output, dim=-1)\n",
        "                # compare predictions to true label\n",
        "                target = target.squeeze(-1).cpu()\n",
        "                total += len(pred)\n",
        "                correct += int(torch.sum(pred == target))\n",
        "        \n",
        "        if total > 0:\n",
        "            accuracy = correct/total\n",
        "        else:\n",
        "            accuracy = 0.0\n",
        "        return accuracy\n",
        "\n",
        "    def predict(self, model, test_loader):\n",
        "        model.eval() # prep model for *evaluation*\n",
        "        predictions = None\n",
        "\n",
        "        for data in test_loader:\n",
        "                data = data.to(self.device)\n",
        "                output = model(data)\n",
        "                # convert output probabilities to predicted class\n",
        "                _, pred = torch.max(output, 1)\n",
        "                if predictions == None:\n",
        "                    predictions = pred\n",
        "                else:\n",
        "                    predictions = torch.cat((predictions, pred))\n",
        "        return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZUFAHkxabqo"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "!pip3 install -U timm > /dev/null\n",
        "import timm\n",
        "from pprint import pprint\n",
        "\n",
        "class OurModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(OurModel, self).__init__()\n",
        "    self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "    self.linear = nn.Linear(1000,100)\n",
        "  def forward(self,input):\n",
        "    return self.linear(self.vit(F.interpolate(input, (224, 224))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph4BC7v6607O"
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--train_loc', type = str, default = './TinyImageNet/train/')\n",
        "parser.add_argument('--val_loc', type = str, default = './TinyImageNet/val/')\n",
        "parser.add_argument('--test_loc', type = str, default = './TinyImageNet/test/')\n",
        "parser.add_argument('--model_name', type = str, default = \"Temp\")\n",
        "args = parser.parse_known_args()[0]\n",
        "\n",
        "dataset = TINDataset(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYoGnJXFbymM"
      },
      "source": [
        "conf = Config(args.model_name)\n",
        "model = OurModel()\n",
        "model.to(device)\n",
        "\n",
        "# 炼丹炉 The Alchemy\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(params = model.parameters(), lr=conf.learning_rate, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DTn_Pvyb6fY"
      },
      "source": [
        "losses = conf.train(model, optimizer, criterion, dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGIU6nVpKsc2"
      },
      "source": [
        "model.load_state_dict(torch.load('./checkpoint/Temp'))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVNLerq1B8ZH"
      },
      "source": [
        "# submit to Kaggle\n",
        "dataset.test()\n",
        "test_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=10)\n",
        "result = conf.predict(model, test_loader)\n",
        "\n",
        "file = open(\"./submit.csv\", mode=\"w\")\n",
        "file.write(\"Id,Category\\n\")\n",
        "for i in range(len(result)):\n",
        "  file.write(str(i) + \".jpg,\" + str(int(result[i])) + \"\\n\")\n",
        "file.flush()\n",
        "file.close()\n",
        "\n",
        "message = input(\"Input submission message: \").strip()\n",
        "!kaggle competitions submit -f submit.csv -m $message deep-learning-thu-2020"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}